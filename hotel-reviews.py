# -*- coding: utf-8 -*-
"""TestTrain P170.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1klPVR4fcE6anzLSpFqYn7ZlBvo3n4kD3
"""

import numpy as np
import pandas as pd
import string # special operations on strings
import spacy # language models
from matplotlib.pyplot import imread
from matplotlib import pyplot as plt
from wordcloud import WordCloud
import seaborn as sns

data=pd.read_excel('hotel_reviews.xlsx')
data

from mpl_toolkits.mplot3d import Axes3D
import plotly.graph_objects as go
import plotly.express as px
from wordcloud import STOPWORDS
import re

data.info() #no null values

data.describe()

data.duplicated().sum() #no duplicates in given dataset

sns.countplot(data['Rating'])

data['Rating'].value_counts()

percent={1421/20491,
6039/20491,2184/20491,1793/20491,9054/20491}
sorted(percent,reverse=True)

import matplotlib.pyplot as plt

# Pie chart, where the slices will be ordered and plotted counter-clockwise:
labels = '1', '2', '3', '4', '5'
sizes = [6.93, 8.7, 10.65, 29.47, 44.18]
explode = (0, 0, 0, 0, 0)  # only "explode" the 2nd slice (i.e. 'Hogs')

fig1, ax1 = plt.subplots()
ax1.pie(sizes, explode=explode, labels=labels, autopct='%1.1f%%',
        shadow=True, startangle=90)
ax1.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.

plt.show()

data['Lenght']=data['Review'].apply(len)
data

data['Lenght'].describe()

sns.lineplot(x='Rating',y='Lenght',data=data)

plt.scatter(x='Rating',y='Lenght',data=data)

df5=data[data['Rating']==5]
df5

plt.figure(figsize=(15,15))
wc1 = WordCloud(max_words=1000, min_font_size=10, 
                height=800,width=800,background_color="white").generate(' '.join(df5['Review']))

plt.imshow(wc1)

df4=data[data['Rating']==4]
df4

plt.figure(figsize=(15,15))
wc2 = WordCloud(max_words=1000, min_font_size=10, 
                height=800,width=800,background_color="white").generate(' '.join(df4['Review']))

plt.imshow(wc2)

df3=data[data['Rating']==3]
df3

plt.figure(figsize=(15,15))
wc3 = WordCloud(max_words=1000, min_font_size=10, 
                height=800,width=800,background_color="white").generate(' '.join(df3['Review']))

plt.imshow(wc3)

df2=data[data['Rating']==2]
df2

plt.figure(figsize=(15,15))
wc4 = WordCloud(max_words=1000, min_font_size=10, 
                height=800,width=800,background_color="white").generate(' '.join(df2['Review']))

plt.imshow(wc4)

df1=data[data['Rating']==1]
df1

plt.figure(figsize=(15,15))
wc5 = WordCloud(max_words=1000, min_font_size=10, 
                height=800,width=800,background_color="white").generate(' '.join(df1['Review']))

plt.imshow(wc5)

import nltk
from nltk.corpus import stopwords
from nltk.stem.porter import PorterStemmer

quo=data.iloc[0,0]
quo

quo=re.sub('[^a-zA-Z0-9]',' ',quo)
quo=quo.lower().split()
quo

nltk.download('stopwords')

sw=set(stopwords.words('english'))
print(sw)

clean_word=[i for i in quo if not i in sw]
clean_word

sen=' '.join(clean_word)
sen

def text_preprocessing(quo):
  quo=re.sub('[^a-zA-Z]',' ',quo)
  quo=quo.lower().split()
  ps=PorterStemmer()
  clean_word=[ps.stem(i) for i in quo if not i in sw]
  sen=' '.join(clean_word)
  return sen

data['clean_word']=data["Review"].apply(text_preprocessing)
data.head()

data['Length 2'] = data['clean_word'].apply(len)
data.head()

data.describe()

from nltk.stem import WordNetLemmatizer
from nltk.tokenize import word_tokenize
from nltk.tokenize import WhitespaceTokenizer

lemmatizer = WordNetLemmatizer()
w_tokenizer=WhitespaceTokenizer()

from nltk import pos_tag
import nltk
nltk.download('averaged_perceptron_tagger')
nltk.download('all')

def lemmatize(txt):
  """
  This function takes text string as input lemmatize it to its root/base/stem word.
  """
  list_review=[lemmatizer.lemmatize(word=word, pos=tag[0].lower()) if tag[0].lower() in ['a','r','n','v'] else word for word, tag in pos_tag(w_tokenizer.tokenize(txt))]
  return (' '.join([x for x in list_review if x]))

data['Lemmatized_Review']=data['clean_word'].apply(lambda x: lemmatize(x))

data

data['Length 3'] = data['Lemmatized_Review'].apply(len)
data.head()

data.describe()

def rating(score):
    if score > 3:
        return 'Positive'
    elif score == 3:
        return 'Neutral'
    else:
        return 'Negative'

data['Emotion']=data['Rating'].apply(rating)
data

data['Emotion'].value_counts()

df=pd.read_excel('hotel_reviews.xlsx')
df

df_neg=df.loc[df['Rating']<3]
df_neg=df_neg.reset_index(drop=True)
df_neg

df_neu=df.loc[df['Rating']==3]
df_neu=df_neu.reset_index(drop=True)
df_neu

df_pos=df.loc[df['Rating']>3]
df_pos=df_pos.reset_index(drop=True)
df_pos

datapos=data.loc[data['Rating']>3]
datapos=datapos.reset_index(drop=True)
datapos

dataneg=data.loc[data['Rating']<3]
dataneg=dataneg.reset_index(drop=True)
dataneg

add=data[ (data['Emotion'] == 'Positive') ].index
data.drop(add,inplace=True)
data.reset_index(drop=True)
data

sub=data[ (data['Emotion'] == 'Negative') ].index
data.drop(sub,inplace=True)
data.reset_index(drop=True)
data

df_negi=dataneg.loc[:len(df_neu)]
df_negi

df_posi=datapos.loc[:len(df_neu)]
df_posi

df_pn=pd.concat([df_posi,df_negi],axis=0)
df_pn

DF=pd.concat([df_pn,data],axis=0)
DF

DF['Emotion'].value_counts()

from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score,r2_score
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.neighbors import  KNeighborsClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.ensemble import AdaBoostClassifier
from sklearn.neural_network import  MLPClassifier
from sklearn.svm import SVC
from xgboost import XGBClassifier
from sklearn.naive_bayes import MultinomialNB
from sklearn.feature_extraction.text import CountVectorizer 
from sklearn.preprocessing import LabelEncoder,StandardScaler
from sklearn.metrics import classification_report

cv=CountVectorizer()
x=cv.fit_transform(data["Review"]).toarray()
y=data["Rating"]

X_train, X_test, Y_train, Y_test = train_test_split(DF.Review,DF.Emotion)

X_train_vec=cv.fit_transform(X_train)
X_test_vec=cv.transform(X_test)

#SVM CLassifier

model=SVC(kernel='linear')
model.fit(X_train_vec,Y_train)

pred=model.predict(X_test_vec)
pred

print(classification_report(pred,Y_test))

rev=['the ambience was average']
rev_vec=cv.transform(rev)
model.predict(rev_vec)

#Multinomial NB Classifier

model1=MultinomialNB()
model1.fit(X_train_vec,Y_train)

pred1=model1.predict(X_test_vec)
pred1

print(classification_report(pred1,Y_test))

op=['the bed was ']
op_vec=cv.transform(op)
model1.predict(op_vec)

#XGBoost Classifier

model2=XGBClassifier()
model2.fit(X_train_vec,Y_train)

pred2=model2.predict(X_test_vec)
pred2

print(classification_report(pred2,Y_test))

op=['the ambience is average']
op_vec=cv.transform(op)
model2.predict(op_vec)

#Random Forest

model3=RandomForestClassifier()
model3.fit(X_train_vec,Y_train)

pred3=model3.predict(X_test_vec)
pred3

print(classification_report(pred3,Y_test))

#Ada Boost Classifier

model4=AdaBoostClassifier()
model4.fit(X_train_vec,Y_train)

pred4=model4.predict(X_test_vec)
pred4

print(classification_report(pred4,Y_test))

#Logistic Regression

model5=LogisticRegression()
model5.fit(X_train_vec,Y_train)

pred5=model5.predict(X_test_vec)
pred5

print(classification_report(pred5,Y_test))

rev=['stay bellevue instead write review leisure traveller, hotel superb location beds super comfortable it.the valet parking 35.00 said, rooms not modern way starting 10 year old television, strikes odd lay-out bathroom, open door walk straight wall better sober, step shower foot toilet, not quiet hotel.the noise showers not allow fallback sleep awaken, noise doors closing compared door close 6 hour arguementwith girlfriend boyfriend foundations literallly shake.i nt know want stay hotel prices charged going spend money stay hyatt westin, budget stay bellevue hotels everybit nice better, recommend bellevue athletic club hyatt westin, taxi public transport town save money steak dinner ruth chris']
rev_vec=cv.transform(rev)
model5.predict(rev_vec)

model1 = SVC()
model1.fit(X_train_vec,Y_train)

svm_pred_train=model1.predict(X_train_vec)
svm_pred_test=model1.predict(X_test_vec)
svm_train_acc=accuracy_score(svm_pred_train,Y_train)
svm_test_acc=accuracy_score(svm_pred_test,Y_test)
print('Training Accuracy : ',(svm_train_acc*100).round(2))
print('Testing Accuracy  : ',(svm_test_acc*100).round(2))

print(classification_report(pred,Y_train))

model2 = MultinomialNB()
model2.fit(X_train_vec,Y_train)

mnb_pred_train=model2.predict(X_train_vec)
mnb_pred_test=model2.predict(X_test_vec)
mnb_train_acc=accuracy_score(mnb_pred_train,Y_train)
mnb_test_acc=accuracy_score(mnb_pred_test,Y_test)
print('Training Accuracy : ',(mnb_train_acc*100).round(2))
print('Testing Accuracy  : ',(mnb_test_acc*100).round(2))

print(classification_report(mnb_pred,Y_train))

model3 = LogisticRegression()
model3.fit(X_train_vec,Y_train)

lr_pred_train=model3.predict(X_train_vec)
lr_pred_test=model3.predict(X_test_vec)
lr_train_acc=accuracy_score(lr_pred_train,Y_train)
lr_test_acc=accuracy_score(lr_pred_test,Y_test)
print('Training Accuracy : ',(lr_train_acc*100).round(2))
print('Testing Accuracy  : ',(lr_test_acc*100).round(2))

print(classification_report(lr_pred,Y_train))

rev=['the room temperature was upto mark']
rev_vec=cv.transform(rev)
model3.predict(rev_vec)

md = MultinomialNB()
md.fit(X_train_vec,Y_train)

_pred_train=model3.predict(X_train_vec)
lr_pred_test=model3.predict(X_test_vec)
lr_train_acc=accuracy_score(lr_pred_train,Y_train)
lr_test_acc=accuracy_score(lr_pred_test,Y_test)
print('Training Accuracy : ',(lr_train_acc*100).round(2))
print('Testing Accuracy  : ',(lr_test_acc*100).round(2))